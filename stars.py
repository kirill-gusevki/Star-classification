# -*- coding: utf-8 -*-
"""stars.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JfS2asEOkXSTtZpNeTJ-06Yya0T5NAeA
"""

!pip install opendatasets --quiet

import opendatasets as od

dataset_url = "https://www.kaggle.com/competitions/star-type-classification"

od.download(dataset_url)

import pandas as pd

train = pd.read_csv('/content/star-type-classification/train_star.csv')
test = pd.read_csv('/content/star-type-classification/test_star.csv')
sample_submit = pd.read_csv('/content/star-type-classification/sample_submition_stars.csv')

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

le.fit(train['TargetClass'])
train['TargetClass'] = le.transform(train['TargetClass'])

test[test['SpType'].str.contains('Ia')]

train[train['SpType'].str.contains('Ia')]

import re
train['SpType'] = train['SpType'].str.replace(':', '')
train["SpType"] = train['SpType'].str.split('/')
train["SpType"] = train['SpType'].apply(lambda parts: [
        item
        for part in parts
        # Извлекаем: 1) спектральный класс, 2) светимость (с учетом Ia, Ib, II и т.д.)
        for item in re.findall(r'([A-Z])(?:[0-9]*)([IVXLC]+|I[ab]|II|III|IV|V)?', part)
        for item in filter(None, item)  # Удаляем пустые элементы
    ])
train

target_columns = ['I', 'II', 'III', 'IV', 'V', 'O', 'B', 'A', 'F', 'G', 'K', 'M']

# Создаем dummy-переменные для элементов в SpType
dummies = (train['SpType'].explode().str.get_dummies().groupby(level=0).max())

# Фильтруем только нужные колонки и добавляем отсутствующие
dummies = dummies.reindex(columns=target_columns, fill_value=0)



# Объединяем результат с исходным DataFrame
train = train.join(dummies)
train

train.drop(columns=["SpType"], inplace=True)

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(train.corr(), annot = True, cmap="YlGnBu", linecolor='white',linewidths=0.5)

train["TargetClass"].value_counts()

train.info()

train

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss
from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN
from collections import Counter

# Разделение на признаки и целевую переменную (замените 'label' на имя вашего целевого столбца)
X = train.drop(columns = ["TargetClass"])
y = train['TargetClass']

# Разделение на train/test с сохранением распределения классов
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

# Проверка распределения классов
print("Train распределение:", Counter(y_train))
print("Test распределение:", Counter(y_test))
print("\nClass counts:")
print(f"Train Giants (1): {sum(y_train == 1)}, Dwarfs (0): {sum(y_train == 0)}")
print(f"Test Giants (1): {sum(y_test == 1)}, Dwarfs (0): {sum(y_test == 0)}")

# Инициализация модели
model = DecisionTreeClassifier(random_state=42)

# Функция для оценки
def evaluate_model(model, X_train, y_train, X_test, y_test, method_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    return {
        'Method': method_name,
        'Accuracy': round(accuracy_score(y_test, y_pred), 3),
        'f1_macro': round(f1_score(y_test, y_pred, average='macro'), 3),
        'f1_weighted': round(f1_score(y_test, y_pred, average='weighted'), 3),
        'Recall': round(recall_score(y_test, y_pred, average='macro'), 3),
        'Precision': round(precision_score(y_test, y_pred, average='macro'), 3)
    }

results = []

# 1. Без балансировки
results.append(evaluate_model(model, X_train, y_train, X_test, y_test, "No Balancing"))

# 2. Random Undersampling
rus = RandomUnderSampler(random_state=42)
X_rus, y_rus = rus.fit_resample(X_train, y_train)
results.append(evaluate_model(model, X_rus, y_rus, X_test, y_test, "Random Undersampling"))

# 3. TomekLinks + Random Undersampling
tomek = TomekLinks()
X_tomek, y_tomek = tomek.fit_resample(X_train, y_train)
rus = RandomUnderSampler(random_state=42)
X_tomek_rus, y_tomek_rus = rus.fit_resample(X_tomek, y_tomek)
results.append(evaluate_model(model, X_tomek_rus, y_tomek_rus, X_test, y_test, "Tomek + Undersampling"))

# 4. NearMiss
nearmiss = NearMiss(version=2)
X_nm, y_nm = nearmiss.fit_resample(X_train, y_train)
results.append(evaluate_model(model, X_nm, y_nm, X_test, y_test, "NearMiss"))

# 5. Random Oversampling
ros = RandomOverSampler(random_state=42)
X_ros, y_ros = ros.fit_resample(X_train, y_train)
results.append(evaluate_model(model, X_ros, y_ros, X_test, y_test, "Random Oversampling"))

# 6. SMOTE
smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X_train, y_train)
results.append(evaluate_model(model, X_smote, y_smote, X_test, y_test, "SMOTE"))

# 7. ADASYN
adasyn = ADASYN(random_state=42)
X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)
results.append(evaluate_model(model, X_adasyn, y_adasyn, X_test, y_test, "ADASYN"))

# Результаты
results_df = pd.DataFrame(results)
print("\nРезультаты сравнения методов:")
print(results_df.to_markdown(index=False, tablefmt="grid"))

from sklearn.model_selection import cross_validate
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
import warnings
warnings.filterwarnings("ignore")

# Инициализация моделей
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "KNN": KNeighborsClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
}

# Определение метрик для классификации
scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']

results = {}

# Кросс-валидация для каждой модели
for name, model in models.items():
    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)

    results[name] = {
        'Accuracy': np.mean(cv_results['test_accuracy']),
        'Precision': np.mean(cv_results['test_precision_macro']),
        'Recall': np.mean(cv_results['test_recall_macro']),
        'F1-Score': np.mean(cv_results['test_f1_macro'])
    }

# Создание DataFrame с результатами
results_df = pd.DataFrame.from_dict(results, orient='index').sort_values('F1-Score', ascending=False)

# Визуализация результатов
plt.figure(figsize=(15, 10))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
for i, metric in enumerate(metrics, 1):
    plt.subplot(2, 2, i)
    sns.barplot(x=results_df.index, y=results_df[metric], palette='viridis')
    plt.title(f'{metric} Comparison')
    plt.xticks(rotation=45)
    plt.ylim(0, 1)  # Ограничение для метрик классификации

plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 10))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
for i, metric in enumerate(metrics, 1):
    plt.subplot(2, 2, i)
    sns.barplot(x=results_df.index, y=results_df[metric], palette='viridis')
    plt.title(f'{metric} Comparison')
    plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

results_df

from sklearn.model_selection import GridSearchCV

# Определяем модель
rf_model = RandomForestClassifier(random_state=42)

# Определяем параметры для поиска
param_grid = {
    'n_estimators': [100, 200, 300, 500],  # Количество деревьев
    'max_depth': [10, 20, 30],  # Максимальная глубина деревьев
    'min_samples_split': [2, 5, 10],  # Минимальное количество сэмплов для разбиения узла
    'min_samples_leaf': [2, 4, 6],  # Минимальное количество сэмплов в листе
    'max_features': ['auto', 'sqrt', 'log2'],  # Количество признаков для поиска лучшего разбиения
}

# Инициализация GridSearchCV
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='recall', verbose=2)

# Обучение на данных
grid_search.fit(X, y)

# Вывод лучших параметров
print("Best parameters found: ", grid_search.best_params_)

# Оценка модели с лучшими гиперпараметрами
best_model = grid_search.best_estimator_
best_score = grid_search.best_score_

print(f"Best score (recall): {best_score:.4f}")

X = train.drop(columns = ["TargetClass"])
y = train['TargetClass']
adasyn = ADASYN(random_state=42)
X_final_bal, y_final_bal = adasyn.fit_resample(X, y)

final_model = RandomForestClassifier(
    max_depth=20,
    max_features='sqrt',
    min_samples_leaf=2,
    min_samples_split=5,
    n_estimators=100,
    random_state=42
)

final_model.fit(X_final_bal, y_final_bal)

test['SpType'] = test['SpType'].str.replace(':', '')
test["SpType"] = test['SpType'].str.split('/')
test["SpType"] = test['SpType'].apply(lambda parts: [
        item
        for part in parts
        # Извлекаем: 1) спектральный класс, 2) светимость (с учетом Ia, Ib, II и т.д.)
        for item in re.findall(r'([A-Z])(?:[0-9]*)([IVXLC]+|I[ab]|II|III|IV|V)?', part)
        for item in filter(None, item)  # Удаляем пустые элементы
    ])
test

target_columns = ['I', 'II', 'III', 'IV', 'V', 'O', 'B', 'A', 'F', 'G', 'K', 'M']

# Создаем dummy-переменные для элементов в SpType
dummies = (test['SpType'].explode().str.get_dummies().groupby(level=0).max())

# Фильтруем только нужные колонки и добавляем отсутствующие
dummies = dummies.reindex(columns=target_columns, fill_value=0)



# Объединяем результат с исходным DataFrame
test = test.join(dummies)
test

test.drop(columns=["SpType"], inplace=True)

test

y_pred_test = final_model.predict(test)
y_pred_test

ans_df = pd.DataFrame(y_pred_test, columns=['TargetClass'])

ans_df.reset_index(inplace=True)

ans_df.to_csv('submition_v1.csv', index=False)